{
  
    
        "post0": {
            "title": "Tilt experiments",
            "content": "Small experiments for how gradients of spatial frequency filters may be perceived as 3D tilts. . First include ImageJ and the mpicbg library that includes a useful integral image implementation and transformation models: . %maven net.imagej:ij:1.53s %maven mpicbg:mpicbg_:1.4.0 import ij.*; import ij.process.*; import java.util.*; import mpicbg.ij.integral.*; . We want to fill images with white noise, so here are two functions to do so: . void fillWhiteNoise(final FloatProcessor ip) { final var rnd = new Random(0); final float[] pixels = (float[])ip.getPixels(); for (int i = 0; i &lt; pixels.length; ++i) pixels[i] = rnd.nextFloat() * 2 - 1; } void fillGaussianNoise(final FloatProcessor ip) { final var rnd = new Random(0); final float[] pixels = (float[])ip.getPixels(); for (int i = 0; i &lt; pixels.length; ++i) pixels[i] = (float)rnd.nextGaussian(); } . This is the Tilt class from mpicbg but with protected members so we can extend it. It implements a the miniature fake method for photography where the image is blurred with an increasingly smooth kernel whose size depends on the distance from a &#39;focal line&#39; in the image. This blur gradient is parameterized with a line segment that is perpedicular to the &#39;focal line&#39; and whose length defines the speed at which the blur filter size increases: . public class Tilt { final protected IntegralImage integral; final protected ImageProcessor ip; public Tilt(final ColorProcessor ip) { this.ip = ip; integral = new LongRGBIntegralImage(ip); } public Tilt(final ByteProcessor ip) { this.ip = ip; integral = new LongIntegralImage(ip); } public Tilt(final ShortProcessor ip) { this.ip = ip; integral = new LongIntegralImage( ip ); } public Tilt(final FloatProcessor ip) { this.ip = ip; integral = new DoubleIntegralImage(ip); } public void setPixel( final int x, final int y, final int xMin, final int yMin, final int xMax, final int yMax, final float scale) { ip.set(x, y, integral.getScaledSum(xMin, yMin, xMax, yMax, scale)); } public void render(final int x1, final int y1, final int x2, final int y2) { final int w = ip.getWidth() - 1; final int h = ip.getHeight() - 1; final double s = (ip.getWidth() + ip.getHeight()) * 2.0; final int dx = x2 - x1; final int dy = y2 - y1; for (int y = 0; y &lt;= h; ++y) { final double yt = y - y1; for (int x = 0; x &lt;= w; ++x) { final double xt = x - x1; final double r = (dx * xt + dy * yt) / s; final int ri = r &lt; 0 ? (int)-r : (int)r; final int yMin = Math.max(-1, y - ri - 1); final int yMax = Math.min(h, y + ri); final int xMin = Math.max(-1, x - ri - 1); final int xMax = Math.min(w, x + ri); final float scale = 1.0f / (xMax - xMin) / (yMax - yMin); setPixel(x, y, xMin, yMin, xMax, yMax, scale); } } } } . Now a variant of the Tilt class that does not normalize the sum of the blur filter by the number of pixels but by the square root of the number of pixels: . public class Tilt2 extends Tilt { public Tilt2(final ColorProcessor ip) { super(ip); } public Tilt2(final ByteProcessor ip) { super(ip); } public Tilt2(final ShortProcessor ip) { super(ip); } public Tilt2(final FloatProcessor ip) { super(ip); } public void setPixel( final int x, final int y, final int xMin, final int yMin, final int xMax, final int yMax, final float scale) { ip.set(x, y, integral.getScaledSum(xMin, yMin, xMax, yMax, (float)Math.sqrt(scale))); } } . Let&#39;s make an image and fill it with noise. We create an image that is 10 times larger than what we want to display so we can use area averaging to present a downscaled version with minimal aliasing: . final int scale = 10; var ip = new FloatProcessor(512 * scale, 512 * scale); fillWhiteNoise(ip); ip.setMinAndMax(-2, 2); Scale.create(ip).scale(1.0 / scale).getBufferedImage(); . Now lets filter this with box filters of increasing size along a vertical gradient: . var ip2 = ip.duplicate(); var tilt2 = new Tilt2((FloatProcessor)ip2); tilt2.render(0, 0, 0, 127); Scale.create(ip2).scale(1.0 / scale).getBufferedImage(); . And now the same with a horizontal gradient: . var ip2 = ip.duplicate(); var tilt2 = new Tilt2((FloatProcessor)ip2); tilt2.render(0, 0, 127, 0); Scale.create(ip2).scale(1.0 / scale).getBufferedImage(); . Or a bit tilted: . var ip2 = ip.duplicate(); var tilt2 = new Tilt2((FloatProcessor)ip2); tilt2.render(0, 0, 63, 127); Scale.create(ip2).scale(1.0 / scale).getBufferedImage(); .",
            "url": "https://saalfeldlab.github.io/blog/integral%20image/imagej/tilt/frequency%20filter/mpicbg/2022/07/22/tilt-noise.html",
            "relUrl": "/integral%20image/imagej/tilt/frequency%20filter/mpicbg/2022/07/22/tilt-noise.html",
            "date": " • Jul 22, 2022"
        }
        
    
  
    
        ,"post1": {
            "title": "Integral image mapping",
            "content": "Small experiments for rendering transformed images without aliasing artifacts. We use integral images to approximate an appropriately scaled kernel for each target pixel with a box filter of the size of one scaled pixel. . First include ImageJ and the mpicbg library that includes a useful integral image implementationa and transformation models: . %mavenRepo scijava.public https://maven.scijava.org/content/groups/public %maven net.imagej:ij:1.53s %maven mpicbg:mpicbg_:1.4.0 %maven sc.fiji:panorama_:3.0.2 import ij.*; import ij.process.*; import java.util.*; import mpicbg.ij.*; import mpicbg.ij.integral.*; import mpicbg.models.*; import mpicbg.panorama.*; . This is the TransformMapping class from mpicbg but with a member source, so we can make and re-use an integral image for all subsequent mappings: . public class PrettyMapping&lt;T extends CoordinateTransform&gt; { final protected IntegralImage integral; final protected ImageProcessor source; final protected T transform; final public T getTransform(){ return transform; } private static final IntegralImage integrate(final ImageProcessor ip) { if (FloatProcessor.class.isInstance(ip)) return new DoubleIntegralImage((FloatProcessor)ip); else if (ByteProcessor.class.isInstance(ip)) return new LongIntegralImage((ByteProcessor)ip); else if (ShortProcessor.class.isInstance(ip)) return new LongIntegralImage((ShortProcessor)ip); else if (ColorProcessor.class.isInstance(ip)) return new LongRGBIntegralImage((ColorProcessor)ip); else return null; } private static final double squareLength( final double x0, final double y0, final double x1, final double y1) { final double dx = x1 - x0; final double dy = y1 - y0; return dx * dx + dy * dy; } private static final double length( final double x0, final double y0, final double x1, final double y1) { return Math.sqrt(squareLength(x0, y0, x1, y1)); } public PrettyMapping( final ImageProcessor source, final T transform) { this.source = source; this.transform = transform; this.integral = integrate(source); } public void map(final ImageProcessor target) { source.setInterpolationMethod(ImageProcessor.BICUBIC); final double[] t = new double[3]; final int sw = source.getWidth() - 1; final int sh = source.getHeight() - 1; final int tw = target.getWidth(); final int th = target.getHeight(); for (int y = 0; y &lt;= th; ++y) { final double y0 = y - 0.5; final double y1 = y + 0.5; for (int x = 0; x &lt;= tw; ++x) { t[0] = x; t[1] = y; t[2] = 1.0; transform.applyInPlace(t); final double t0 = t[0]; final double t1 = t[1]; if (t0 &gt;= 0 &amp;&amp; t0 &lt;= sw &amp;&amp; t1 &gt;= 0 &amp;&amp; t1 &lt;= sh) { final double x0 = x - 0.5; final double x1 = x + 0.5; t[0] = x0; t[1] = y0; t[2] = 1.0; transform.applyInPlace(t); final double x00 = t[0]; final double y00 = t[1]; t[0] = x1; t[1] = y0; t[2] = 1.0; transform.applyInPlace(t); final double x10 = t[0]; final double y10 = t[1]; t[0] = x0; t[1] = y1; t[2] = 1.0; transform.applyInPlace(t); final double x01 = t[0]; final double y01 = t[1]; t[0] = x1; t[1] = y1; t[2] = 1.0; transform.applyInPlace(t); final double x11 = t[0]; final double y11 = t[1]; final double avgHalfLength = ( length(x00, y00, x10, y10) + length(x10, y10, x11, y11) + length(x11, y11, x01, y01) + length(x01, y01, x00, y00)) / 8.0; if (avgHalfLength &gt; 1) { final int tx = (int)(t0 + 0.5); final int ty = (int)(t1 + 0.5); final int r = (int)(avgHalfLength + 0.5); final int xMin = Math.max(-1, tx - r - 1); final int xMax = Math.min(sw, tx + r); final int yMin = Math.max(-1, ty - r - 1); final int yMax = Math.min(sh, ty + r); final float scale = 1.0f / (xMax - xMin) / (yMax - yMin); target.set(x, y, integral.getScaledSum(xMin, yMin, xMax, yMax, scale)); } else target.putPixel(x, y, source.getPixelInterpolated(t0, t1)); } } } } } . Let&#39;s load an image from somewhere. This one is large, so we scale it down a bit and display it even smaller: . ImagePlus imp = IJ.openImage(&quot;https://pixy.org/src2/680/6804381.jpg&quot;); var ip = imp.getProcessor(); ip.setMinAndMax(64, 255 - 64); //ip.getBufferedImage(); var ipScaled = Scale.create(ip).scale(0.4); Scale.create(ipScaled).scale(0.5).getBufferedImage(); . Now we transform this with a perspective transformation: . double w = ipScaled.getWidth(); double h = ipScaled.getHeight(); double d = 500; var homography = new HomographyModel2D(); homography.fit( new double[][]{ {d, w - d, -d, w + d}, {0, 0, h - 2 * d, h - 2 * d}}, new double[][]{ {0, w, 0, w}, {0, 0, h, h}}, new double[]{1, 1, 1, 1}); var mapping = new PrettyMapping(ipScaled, homography); var ip2 = ip.createProcessor((int)w, (int)h - 2 * (int)d); mapping.map(ip2); Scale.create(ip2).scale(0.5).getBufferedImage(); . Now let&#39;s see how it looks with interpolation only, i.e. if the kernel does not integrate over transformed pixels that are larger than one source pixel: . var mapping2 = new TransformMapping(homography); var ip3 = ip.createProcessor((int)w, (int)h - 2 * (int)d); mapping2.mapInverseInterpolated(ipScaled, ip3); Scale.create(ip3).scale(0.5).getBufferedImage(); . Now let&#39;s do an experiment with a proper camera model. We can use the RectlinearCamera from Fiji&#39;s panorama viewer, but to use this with PrettyMapping we have to run it through a facade that applies the inverse of the transformation instead of the forward: . public class InverseOf implements CoordinateTransform { protected InverseCoordinateTransform t; public InverseOf(final InverseCoordinateTransform t) { this.t = t; } public void applyInPlace(final double[] point) { try { t.applyInverseInPlace(point); } catch (final NoninvertibleModelException e ) { display(e); } } public double[] apply(final double[] point) { final double[] copy = point.clone(); applyInPlace(copy); return copy; } } . double w = ipScaled.getWidth(); double h = ipScaled.getHeight(); double d = 1000; var camera = new RectlinearCamera(); camera.setSourceWidth(w - 1); camera.setSourceHeight(h - 1); camera.setTargetWidth(w); camera.setTargetHeight(h); camera.setF(0.125); camera.pan(Math.PI * 0.05); var mapping = new PrettyMapping(ipScaled, new InverseOf(camera)); var ip2 = ip.createProcessor((int)camera.getTargetWidth(), (int)camera.getTargetHeight()); mapping.map(ip2); camera.pan(-Math.PI / 2); mapping.map(ip2); Scale.create(ip2).scale(0.5).getBufferedImage(); .",
            "url": "https://saalfeldlab.github.io/blog/integral%20image/imagej/antialiazing/transformation/mpicbg/2022/07/22/integral-image-mapping.html",
            "relUrl": "/integral%20image/imagej/antialiazing/transformation/mpicbg/2022/07/22/integral-image-mapping.html",
            "date": " • Jul 22, 2022"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About",
          "content": "This blog is for news and chatter . The Saalfeld lab develops scalable image analysis methods as open source software. We use this blog to post unfinished scripts and ideas and to communicate stuff that didn’t work out. .",
          "url": "https://saalfeldlab.github.io/blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://saalfeldlab.github.io/blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}